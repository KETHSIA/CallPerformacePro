{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-G_Y2V88K0X"
      },
      "source": [
        "# Speech Emotion Recognition using Librosa\n",
        "\n",
        "\n",
        "#### RAVDESS Dataset\n",
        "This is the Ryerson Audio-Visual Database of Emotional Speech and Song dataset, and is free to download. This dataset has 7356 files rated by 247 individuals 10 times on emotional validity, intensity, and genuineness. The entire dataset is 24.8GB from 24 actors.\n",
        "\n",
        "Dataset on Google Drive: https://drive.google.com/file/d/1wWsrN2Ep7x6lWqOXfr4rpKGYrJhWc8z7/view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byp8AEbuxqys",
        "outputId": "7a55730a-f823-4699-b258-895008639f85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "#Connect your Drive with Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMcSXcrCyUHB",
        "outputId": "6f7f3850-c778-4535-d130-ccf49260093e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actor_01  Actor_04  Actor_07  Actor_10\tActor_13  Actor_16  Actor_19  Actor_22\n",
            "Actor_02  Actor_05  Actor_08  Actor_11\tActor_14  Actor_17  Actor_20  Actor_23\n",
            "Actor_03  Actor_06  Actor_09  Actor_12\tActor_15  Actor_18  Actor_21  Actor_24\n"
          ]
        }
      ],
      "source": [
        "#Check where your Dataset Zip File is\n",
        "!ls '/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iQOY709my-fv"
      },
      "outputs": [],
      "source": [
        "# #Unzip the file contents\n",
        "# !unzip '/content/drive/My Drive/Important Extras/Data Science Works/_Data Science Work/Speech Emotion Recognition/speech-emotion-recognition-ravdess-data.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9dIRJbovpGI",
        "outputId": "c700aba7-fd17-486a-c5ed-14f13524c10c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "#You can see the zip folder has been extracted\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utFTMFyG4fdC",
        "outputId": "6515f3e2-05bf-4e28-a453-9a0315e12453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.6.2)\n"
          ]
        }
      ],
      "source": [
        "#Install Librosa and SoundFile to your Machine\n",
        "!pip install librosa soundfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kZTfgUu51RCX"
      },
      "outputs": [],
      "source": [
        "#Import All Important Libraries\n",
        "import librosa\n",
        "import soundfile\n",
        "import os, glob, pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dvGpG07E_3Uo"
      },
      "outputs": [],
      "source": [
        "def extract_feature(file_name, mfcc, chroma, mel, max_length=100):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate = sound_file.samplerate\n",
        "        result = np.array([])\n",
        "        if mfcc:\n",
        "            mfccs = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40)\n",
        "            mfccs_mean = np.mean(mfccs, axis=0)\n",
        "            mfccs_padded = pad_or_truncate(mfccs_mean, max_length)\n",
        "            result = np.hstack((result, mfccs_padded))\n",
        "        if chroma:\n",
        "            stft = np.abs(librosa.stft(X))\n",
        "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
        "            chroma_padded = pad_or_truncate(chroma, max_length)\n",
        "            result = np.hstack((result, chroma_padded))\n",
        "        if mel:\n",
        "            mel = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T, axis=0)\n",
        "            mel_padded = pad_or_truncate(mel, max_length)\n",
        "            result = np.hstack((result, mel_padded))\n",
        "    return result\n",
        "\n",
        "def pad_or_truncate(feature, max_length):\n",
        "    if len(feature) < max_length:\n",
        "        # If feature is shorter than max_length, pad with zeros\n",
        "        return np.pad(feature, (0, max_length - len(feature)), mode='constant')\n",
        "    else:\n",
        "        # If feature is longer than max_length, truncate\n",
        "        return feature[:max_length]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "p-UIAg03Xis1"
      },
      "outputs": [],
      "source": [
        "#Define the motions dictionary\n",
        "emotions = {\n",
        "    '01':'neutral',\n",
        "    '02':'calm',\n",
        "    '03':'happy',\n",
        "    '04':'sad',\n",
        "    '05':'angry',\n",
        "    '06':'fearful',\n",
        "    '07':'disgust',\n",
        "    '08':'surprised'\n",
        "}\n",
        "\n",
        "#Emotions we want to observe\n",
        "observed_emotions = ['calm', 'happy', 'fearful', 'disgust']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmmDYip41hk9",
        "outputId": "ea67beee-f7b8-444d-f8a9-86f85b0e87d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_23\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_20\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_24\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_22\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_19\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_18\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_21\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_11\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_15\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_14\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_12\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_17\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_13\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_16\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_10\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_08\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_09\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_03\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_06\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_04\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_01\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_02\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_07\n",
            "/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_05\n",
            "(614, 154)\n",
            "Features extracted: 300\n"
          ]
        }
      ],
      "source": [
        "# Load the data and extract features for each sound file\n",
        "def load_data(data_dir, test_size=0.2):\n",
        "    x, y = [], []\n",
        "    for folder in glob.glob(os.path.join(data_dir, 'Actor_*')):\n",
        "        print(folder)\n",
        "        for file in glob.glob(os.path.join(folder, '*.wav')):\n",
        "            file_name = os.path.basename(file)\n",
        "            emotion = emotions[file_name.split('-')[2]]\n",
        "            if emotion not in observed_emotions:\n",
        "                continue\n",
        "            feature = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
        "            x.append(feature)\n",
        "            y.append(emotion)\n",
        "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)\n",
        "\n",
        "# Specify the path to your dataset directory\n",
        "data_dir = '/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data'\n",
        "\n",
        "# Load the data\n",
        "x_train, x_test, y_train, y_test = load_data(data_dir)\n",
        "\n",
        "# Shape of train and test set and number of features extracted\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "print(f'Features extracted: {x_train.shape[1]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "154OQUcVZ4tt"
      },
      "outputs": [],
      "source": [
        "# #Load the data and extract features for each sound file\n",
        "# def load_data(test_size = 0.2):\n",
        "#   x, y = [], []\n",
        "#   for folder in glob.glob('/content/Actor_*'):\n",
        "#     print(folder)\n",
        "#     for file in glob.glob(folder + '/*.wav'):\n",
        "#       file_name = os.path.basename(file)\n",
        "#       emotion = emotions[file_name.split('-')[2]]\n",
        "#       if emotion not in observed_emotions:\n",
        "#         continue\n",
        "#       feature = extract_feature(file, mfcc = True, chroma = True, mel = True)\n",
        "#       x.append(feature)\n",
        "#       y.append(emotion)\n",
        "#   return train_test_split(np.array(x), y, test_size = test_size, random_state = 9)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kg9ZfDc5zp0",
        "outputId": "924011d0-18ef-453d-a92d-1eed8fc0f163"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SwRRRmds5fDQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Initialize MLPClassifier with expected parameters\n",
        "model = MLPClassifier(activation='relu', alpha=0.01, batch_size=256, beta_1=0.9,\n",
        "                      beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
        "                      hidden_layer_sizes=(300,), learning_rate='adaptive',\n",
        "                      learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
        "                      momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
        "                      power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
        "                      tol=0.0001, validation_fraction=0.1, verbose=False,\n",
        "                      warm_start=False)\n",
        "\n",
        "# Now you can fit the model, predict, and evaluate as usual\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZXwY7HVDuuTv"
      },
      "outputs": [],
      "source": [
        "# #Initialise Multi Layer Perceptron Classifier\n",
        "model = MLPClassifier(alpha = 0.01, batch_size = 256, epsilon = 1e-08, hidden_layer_sizes = (300,), learning_rate = 'adaptive', max_iter = 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "0_LKbQ3KvJy-",
        "outputId": "ff1d7d7d-cdc0-4672-f468-744885d845c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
              "              learning_rate='adaptive', max_iter=500)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
              "              learning_rate=&#x27;adaptive&#x27;, max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
              "              learning_rate=&#x27;adaptive&#x27;, max_iter=500)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "glTuS50TwN0I"
      },
      "outputs": [],
      "source": [
        "#Predict for the test set\n",
        "y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHeAHwQSUtDr",
        "outputId": "c58702c9-a437-44ff-b3dd-4005dbaef67b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['fearful', 'calm', 'calm', 'happy', 'happy', 'calm', 'fearful',\n",
              "       'happy', 'calm', 'happy', 'fearful', 'happy', 'fearful', 'fearful',\n",
              "       'fearful', 'calm', 'happy', 'calm', 'fearful', 'happy', 'calm',\n",
              "       'fearful', 'fearful', 'calm', 'fearful', 'happy', 'happy', 'happy',\n",
              "       'happy', 'calm', 'happy', 'calm', 'happy', 'happy', 'happy',\n",
              "       'calm', 'happy', 'happy', 'calm', 'calm', 'happy', 'happy',\n",
              "       'happy', 'happy', 'calm', 'happy', 'calm', 'calm', 'happy',\n",
              "       'happy', 'calm', 'happy', 'happy', 'calm', 'happy', 'happy',\n",
              "       'fearful', 'happy', 'happy', 'happy', 'calm', 'happy', 'calm',\n",
              "       'fearful', 'happy', 'happy', 'happy', 'happy', 'happy', 'calm',\n",
              "       'happy', 'calm', 'calm', 'calm', 'happy', 'calm', 'calm', 'happy',\n",
              "       'happy', 'happy', 'fearful', 'calm', 'calm', 'disgust', 'calm',\n",
              "       'disgust', 'happy', 'calm', 'calm', 'calm', 'calm', 'fearful',\n",
              "       'happy', 'calm', 'disgust', 'happy', 'calm', 'calm', 'calm',\n",
              "       'happy', 'happy', 'calm', 'disgust', 'calm', 'calm', 'happy',\n",
              "       'fearful', 'happy', 'calm', 'happy', 'happy', 'calm', 'happy',\n",
              "       'fearful', 'happy', 'calm', 'calm', 'calm', 'calm', 'fearful',\n",
              "       'calm', 'calm', 'happy', 'calm', 'calm', 'calm', 'fearful',\n",
              "       'happy', 'happy', 'happy', 'happy', 'calm', 'fearful', 'happy',\n",
              "       'calm', 'happy', 'happy', 'happy', 'calm', 'happy', 'happy',\n",
              "       'happy', 'calm', 'happy', 'happy', 'happy', 'fearful', 'disgust',\n",
              "       'calm', 'calm', 'fearful', 'happy', 'calm', 'happy'], dtype='<U7')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqVnMdQmwUXG",
        "outputId": "7e5725c5-67de-4f36-950b-0a8716b1344b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 45.45%\n"
          ]
        }
      ],
      "source": [
        "#Calculate Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KxOfHBXsWJEw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "dJMnbT63WLRS",
        "outputId": "22897acd-161e-438e-afc9-769d6df0c238"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Actual Predicted\n",
              "0     happy   fearful\n",
              "1      calm      calm\n",
              "2     happy      calm\n",
              "3     happy     happy\n",
              "4   fearful     happy\n",
              "5      calm      calm\n",
              "6     happy   fearful\n",
              "7     happy     happy\n",
              "8   disgust      calm\n",
              "9     happy     happy\n",
              "10    happy   fearful\n",
              "11  disgust     happy\n",
              "12    happy   fearful\n",
              "13  fearful   fearful\n",
              "14  fearful   fearful\n",
              "15  disgust      calm\n",
              "16     calm     happy\n",
              "17     calm      calm\n",
              "18  fearful   fearful\n",
              "19  disgust     happy"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81d3b205-ef19-470e-8f83-df4b51e8c3bf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>happy</td>\n",
              "      <td>fearful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>calm</td>\n",
              "      <td>calm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>happy</td>\n",
              "      <td>calm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>happy</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fearful</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>calm</td>\n",
              "      <td>calm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>happy</td>\n",
              "      <td>fearful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>happy</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>disgust</td>\n",
              "      <td>calm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>happy</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>happy</td>\n",
              "      <td>fearful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>disgust</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>happy</td>\n",
              "      <td>fearful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>fearful</td>\n",
              "      <td>fearful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>fearful</td>\n",
              "      <td>fearful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>disgust</td>\n",
              "      <td>calm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>calm</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>calm</td>\n",
              "      <td>calm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>fearful</td>\n",
              "      <td>fearful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>disgust</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81d3b205-ef19-470e-8f83-df4b51e8c3bf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-81d3b205-ef19-470e-8f83-df4b51e8c3bf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-81d3b205-ef19-470e-8f83-df4b51e8c3bf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-db490a1b-4b8a-4842-b653-2ce9fa770a58\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db490a1b-4b8a-4842-b653-2ce9fa770a58')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-db490a1b-4b8a-4842-b653-2ce9fa770a58 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 154,\n  \"fields\": [\n    {\n      \"column\": \"Actual\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"calm\",\n          \"disgust\",\n          \"happy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"calm\",\n          \"disgust\",\n          \"fearful\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df=pd.DataFrame({'Actual': y_test, 'Predicted':y_pred})\n",
        "df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X84PdFo29P_a",
        "outputId": "acf4029b-7933-4f96-d14b-c5d44afbd44e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in the directory:\n",
            "03-01-01-01-02-02-01.wav\n",
            "03-01-01-01-02-01-01.wav\n",
            "03-01-01-01-01-02-01.wav\n",
            "03-01-03-02-01-02-01.wav\n",
            "03-01-02-01-01-02-01.wav\n",
            "03-01-04-01-01-01-01.wav\n",
            "03-01-03-01-01-01-01.wav\n",
            "03-01-02-02-01-01-01.wav\n",
            "03-01-02-02-02-01-01.wav\n",
            "03-01-02-01-02-02-01.wav\n",
            "03-01-03-02-02-01-01.wav\n",
            "03-01-03-02-02-02-01.wav\n",
            "03-01-02-02-01-02-01.wav\n",
            "03-01-03-01-01-02-01.wav\n",
            "03-01-03-01-02-01-01.wav\n",
            "03-01-03-01-02-02-01.wav\n",
            "03-01-02-01-02-01-01.wav\n",
            "03-01-03-02-01-01-01.wav\n",
            "03-01-02-01-01-01-01.wav\n",
            "03-01-02-02-02-02-01.wav\n",
            "03-01-05-01-01-02-01.wav\n",
            "03-01-04-01-02-02-01.wav\n",
            "03-01-05-02-02-01-01.wav\n",
            "03-01-04-01-01-02-01.wav\n",
            "03-01-06-01-01-01-01.wav\n",
            "03-01-04-02-01-02-01.wav\n",
            "03-01-05-02-01-01-01.wav\n",
            "03-01-05-01-02-02-01.wav\n",
            "03-01-04-02-02-01-01.wav\n",
            "03-01-04-02-02-02-01.wav\n",
            "03-01-05-02-02-02-01.wav\n",
            "03-01-05-01-01-01-01.wav\n",
            "03-01-04-02-01-01-01.wav\n",
            "03-01-04-01-02-01-01.wav\n",
            "03-01-05-02-01-02-01.wav\n",
            "03-01-05-01-02-01-01.wav\n",
            "03-01-06-02-02-01-01.wav\n",
            "03-01-07-01-01-01-01.wav\n",
            "03-01-07-02-01-01-01.wav\n",
            "03-01-07-01-01-02-01.wav\n",
            "03-01-06-01-02-02-01.wav\n",
            "03-01-07-02-02-01-01.wav\n",
            "03-01-07-01-02-01-01.wav\n",
            "03-01-06-01-01-02-01.wav\n",
            "03-01-07-02-01-02-01.wav\n",
            "03-01-08-01-01-02-01.wav\n",
            "03-01-06-02-01-01-01.wav\n",
            "03-01-07-02-02-02-01.wav\n",
            "03-01-08-01-01-01-01.wav\n",
            "03-01-07-01-02-02-01.wav\n",
            "03-01-06-02-01-02-01.wav\n",
            "03-01-06-02-02-02-01.wav\n",
            "03-01-06-01-02-01-01.wav\n",
            "03-01-08-02-02-01-01.wav\n",
            "03-01-08-02-01-01-01.wav\n",
            "03-01-08-01-02-01-01.wav\n",
            "03-01-08-02-02-02-01.wav\n",
            "03-01-08-01-02-02-01.wav\n",
            "03-01-08-02-01-02-01.wav\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define the directory path\n",
        "directory_path = '/content/drive/MyDrive/Speech_Emotion_Detection-master/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_01'\n",
        "\n",
        "# List all files in the directory\n",
        "files = os.listdir(directory_path)\n",
        "\n",
        "# Print the list of files\n",
        "print(\"Files in the directory:\")\n",
        "for file in files:\n",
        "    print(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "eohe3Z-HfH2q"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "# Writing different model files to file\n",
        "with open( 'modelForPrediction1.sav', 'wb') as f:\n",
        "    pickle.dump(model,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMNIhaVBi01l",
        "outputId": "97522e45-d454-413f-aae5-e1f00dc15487"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['calm'], dtype='<U7')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "filename = 'modelForPrediction1.sav'\n",
        "loaded_model = pickle.load(open(filename, 'rb')) # loading the model file from the storage\n",
        "\n",
        "feature=extract_feature(\"/content/drive/MyDrive/Speech_Emotion_Detection-master/speech-emotion-recognition-ravdess-data/Actor_01/03-01-01-01-01-01-01.wav\", mfcc=True, chroma=True, mel=True)\n",
        "\n",
        "feature=feature.reshape(1,-1)\n",
        "\n",
        "prediction=loaded_model.predict(feature)\n",
        "prediction"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}